{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df07ee2",
   "metadata": {},
   "source": [
    "# Loading LSTM from training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bc2261",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/marcus/.pyenv/versions/global_env/lib/python3.11/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkGetErrorLogSize_12_9, version libnvJitLink.so.12",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/global_env/lib/python3.11/site-packages/torch/__init__.py:427\u001b[39m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    426\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymInt\u001b[39;00m:\n\u001b[32m    431\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: /home/marcus/.pyenv/versions/global_env/lib/python3.11/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkGetErrorLogSize_12_9, version libnvJitLink.so.12"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')  # Go up to src/ directory\n",
    "from models import LSTM_model\n",
    "\n",
    "model = LSTM_model(input_size=14)  # 14 features now (was 9)\n",
    "model.load_state_dict(torch.load('lstm_model.pth'))\n",
    "scaler_X, scaler_y = pickle.load(open('scalers.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73556d3",
   "metadata": {},
   "source": [
    "# Evaluate and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee17cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dataset import EnergyPriceDataset, load_and_preprocess_energy_data\n",
    "\n",
    "df = load_and_preprocess_energy_data('../../data/energy_data.csv')\n",
    "\n",
    "feature_cols = [\n",
    "    'Hour', 'day_nr', 'week_nr', 'year', 'month',\n",
    "    'day_of_year_sin', 'day_of_year_cos',\n",
    "    'wind_forecast_dah_mw', 'consumption_forecast_dah_mw',\n",
    "    'temp_forecast_dah_celcius', 'temp_norm_celcius',\n",
    "    'heating_demand_interaction', 'temp_deviation',\n",
    "    'spot_lag1'\n",
    "]\n",
    "target_col = 'spot'\n",
    "\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df[:split_idx]\n",
    "test_df = df[split_idx:]\n",
    "\n",
    "test_features = scaler_X.transform(test_df[feature_cols])\n",
    "test_targets = scaler_y.transform(test_df[[target_col]])\n",
    "\n",
    "sequence_length = 24 # 24 = one day, 168 = one week\n",
    "test_dataset = EnergyPriceDataset(test_features, test_targets, sequence_length)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        pred = model(X_batch)\n",
    "        predictions.extend(pred.squeeze().tolist())\n",
    "        actuals.extend(y_batch.tolist())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(actuals, label='Actual Prices')\n",
    "plt.plot(predictions, label='Predicted Prices')\n",
    "plt.legend()\n",
    "plt.title('LSTM Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Energy Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6297d",
   "metadata": {},
   "source": [
    "## OGD on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb3715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OGD import OGD_Predictor\n",
    "\n",
    "predictions_unscaled = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "actuals_unscaled = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "ogd = OGD_Predictor(alpha=0.1, eta=1, q_init=50)\n",
    "\n",
    "for t in range(len(predictions_unscaled)):\n",
    "    y_pred = predictions_unscaled[t]\n",
    "    y_true = actuals_unscaled[t]\n",
    "    \n",
    "    lower, upper = ogd.get_interval(y_pred)\n",
    "    covered = ogd.update(y_pred, y_true)\n",
    "    \n",
    "    if t % 100 == 0:\n",
    "        error = abs(y_true - y_pred)\n",
    "        width = 2 * ogd.q\n",
    "        threshold = ogd.q\n",
    "        \n",
    "    if t % 100 == 0:\n",
    "        lower, upper = ogd.get_interval(y_pred)\n",
    "        print(f\"t={t}: [{float(lower):.2f}, {float(upper):.2f}], pred={float(y_pred):.2f}, true={float(y_true):.2f}, covered={covered}, q={ogd.q:.2f}\")\n",
    "\n",
    "print(\"\\n \")\n",
    "print(f\"Coverage Rate: {ogd.get_coverage_rate():.3f} (Target: 0.900)\")\n",
    "print(f\"Final Threshold: {ogd.q:.2f}\")\n",
    "print(f\"Average Width: {np.mean(ogd.threshold_history)*2:.2f}\")\n",
    "\n",
    "misses = sum(1 for c in ogd.coverage_history if not c)\n",
    "print(f\"Total Misses: {misses} out of {len(ogd.coverage_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ee9e3",
   "metadata": {},
   "source": [
    "# ECI on output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0: [79.14, 272.38], pred=175.76, true=143.37, covered=True, q=96.62\n",
      "t=100: [105.13, 123.70], pred=114.42, true=120.30, covered=False, q=9.28\n",
      "t=200: [118.28, 197.42], pred=157.85, true=189.85, covered=True, q=39.57\n",
      "t=300: [144.73, 228.93], pred=186.83, true=218.50, covered=True, q=42.10\n",
      "t=400: [243.03, 366.82], pred=304.93, true=386.37, covered=False, q=61.89\n",
      "t=500: [263.49, 373.88], pred=318.68, true=369.32, covered=False, q=55.20\n",
      "t=600: [282.12, 376.57], pred=329.35, true=344.11, covered=True, q=47.23\n",
      "t=700: [101.58, 214.03], pred=157.80, true=166.65, covered=True, q=56.22\n",
      "t=800: [54.51, 108.68], pred=81.60, true=55.45, covered=False, q=27.09\n",
      "t=900: [-22.91, 100.57], pred=38.83, true=-1.68, covered=True, q=61.74\n",
      "t=1000: [172.53, 271.03], pred=221.78, true=181.26, covered=True, q=49.25\n",
      "t=1100: [104.39, 232.03], pred=168.21, true=124.52, covered=True, q=63.82\n",
      "t=1200: [201.62, 310.39], pred=256.01, true=167.05, covered=False, q=54.39\n",
      "t=1300: [58.54, 202.53], pred=130.54, true=32.58, covered=False, q=72.00\n",
      "t=1400: [115.03, 254.61], pred=184.82, true=143.44, covered=True, q=69.79\n",
      "t=1500: [163.13, 246.95], pred=205.04, true=183.94, covered=True, q=41.91\n",
      "t=1600: [191.69, 292.82], pred=242.25, true=217.67, covered=True, q=50.57\n",
      "t=1700: [98.48, 213.77], pred=156.13, true=112.33, covered=True, q=57.64\n",
      "\n",
      " \n",
      "Coverage Rate: 0.695 (Target: 0.900)\n",
      "Final Threshold: 51.14\n",
      "Average Width: 97.64\n",
      "Total Misses: 528 out of 1733\n"
     ]
    }
   ],
   "source": [
    "from OGD import ECI_Predictor\n",
    "\n",
    "predictions_unscaled = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "actuals_unscaled = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "eci = ECI_Predictor(alpha=0.1, eta=5.0, q_init=10, c=1.0, version='basic', eq_function='sigmoid')\n",
    "\n",
    "for t in range(len(predictions_unscaled)):\n",
    "    y_pred = predictions_unscaled[t]\n",
    "    y_true = actuals_unscaled[t]\n",
    "    \n",
    "    lower, upper = eci.get_interval(y_pred)\n",
    "    covered = eci.update(y_pred, y_true)\n",
    "    \n",
    "    if t % 100 == 0:\n",
    "        error = abs(y_true - y_pred)\n",
    "        width = 2 * eci.q\n",
    "        threshold = eci.q\n",
    "        \n",
    "    if t % 100 == 0:\n",
    "        lower, upper = eci.get_interval(y_pred)\n",
    "        print(f\"t={t}: [{float(lower):.2f}, {float(upper):.2f}], pred={float(y_pred):.2f}, true={float(y_true):.2f}, covered={covered}, q={eci.q:.2f}\")\n",
    "print(\"\\n \")\n",
    "print(f\"Coverage Rate: {eci.get_coverage_rate():.3f} (Target: 0.900)\")\n",
    "print(f\"Final Threshold: {eci.q:.2f}\")\n",
    "print(f\"Average Width: {np.mean(eci.threshold_history)*2:.2f}\")\n",
    "\n",
    "misses = sum(1 for c in eci.coverage_history if not c)\n",
    "print(f\"Total Misses: {misses} out of {len(eci.coverage_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vawtxw0xszq",
   "source": "## Confidence Interval Visualization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ooddi7lrz2g",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef get_intervals_from_history(predictions, threshold_history, q_init):\n    \"\"\"Reconstruct intervals from threshold history.\n    \n    threshold_history[t] contains q AFTER the update at time t.\n    The interval at time t uses the q value BEFORE the update (i.e., from t-1).\n    \"\"\"\n    # At t=0, we use q_init; at t>0, we use q from previous step\n    q_values = [q_init] + list(threshold_history[:-1])\n    q_values = np.array(q_values)\n    lowers = predictions - q_values\n    uppers = predictions + q_values\n    return lowers, uppers\n\n# Get intervals for both methods\nogd_lower, ogd_upper = get_intervals_from_history(predictions_unscaled, ogd.threshold_history, q_init=50)\neci_lower, eci_upper = get_intervals_from_history(predictions_unscaled, eci.threshold_history, q_init=10)\n\n# Define zoom window\nzoom_start, zoom_end = 500, 700\ntime_steps = np.arange(len(predictions_unscaled))\n\n# Create 2x2 subplot\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\ndef plot_ci(ax, time_range, lower, upper, preds, actuals, title, color, is_zoomed=False):\n    \"\"\"Plot confidence interval on a given axis.\"\"\"\n    t = time_range\n    ax.fill_between(t, lower[t], upper[t], alpha=0.3, color=color, label='90% CI')\n    ax.plot(t, actuals[t], color='black', linewidth=1.2, label='Actual', alpha=0.9)\n    ax.plot(t, preds[t], color='red', linewidth=1, label='Predicted', alpha=0.7, linestyle='--')\n    ax.set_title(title)\n    ax.set_xlabel('Time Step')\n    ax.set_ylabel('Price (DKK/MWh)')\n    ax.legend(loc='upper right')\n    ax.grid(True, alpha=0.3)\n\n# OGD plots\nogd_coverage = ogd.get_coverage_rate()\nplot_ci(axes[0, 0], range(zoom_start, zoom_end), ogd_lower, ogd_upper, \n        predictions_unscaled, actuals_unscaled, \n        f'OGD - Zoomed (t={zoom_start}-{zoom_end}) | Coverage: {ogd_coverage:.1%}', 'blue')\n\nplot_ci(axes[0, 1], range(len(predictions_unscaled)), ogd_lower, ogd_upper,\n        predictions_unscaled, actuals_unscaled,\n        f'OGD - Full Series | Coverage: {ogd_coverage:.1%}', 'blue')\n\n# ECI plots  \neci_coverage = eci.get_coverage_rate()\nplot_ci(axes[1, 0], range(zoom_start, zoom_end), eci_lower, eci_upper,\n        predictions_unscaled, actuals_unscaled,\n        f'ECI - Zoomed (t={zoom_start}-{zoom_end}) | Coverage: {eci_coverage:.1%}', 'green')\n\nplot_ci(axes[1, 1], range(len(predictions_unscaled)), eci_lower, eci_upper,\n        predictions_unscaled, actuals_unscaled,\n        f'ECI - Full Series | Coverage: {eci_coverage:.1%}', 'green')\n\nplt.suptitle('LSTM Predictions with Online Conformal Prediction Intervals', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}