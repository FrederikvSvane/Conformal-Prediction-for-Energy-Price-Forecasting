{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3407a0a3",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "783bff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')  # Go up to src/ directory\n",
    "from models import LSTM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb9179",
   "metadata": {},
   "source": [
    "# Setting up data and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c043fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dataset import EnergyPriceDataset, load_and_preprocess_energy_data\n",
    "\n",
    "df = load_and_preprocess_energy_data('../../data/energy_data.csv')\n",
    "\n",
    "feature_cols = ['Hour', 'day_nr', 'week_nr', 'year', 'wind_forecast_dah_mw', 'consumption_forecast_dah_mw', 'temp_forecast_dah_celcius', 'temp_norm_celcius', 'spot_lag1']\n",
    "target_col = 'spot'\n",
    "\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df[:split_idx]\n",
    "test_df = df[split_idx:]\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# train_features = train_df[feature_cols].values.astype(np.float32)\n",
    "# train_targets = train_df[target_col].values.astype(np.float32)\n",
    "\n",
    "# test_features = test_df[feature_cols].values.astype(np.float32)\n",
    "# test_targets = test_df[target_col].values.astype(np.float32)\n",
    "\n",
    "train_features = scaler_X.fit_transform(train_df[feature_cols])\n",
    "train_targets = scaler_y.fit_transform(train_df[[target_col]])\n",
    "\n",
    "test_features = scaler_X.transform(test_df[feature_cols])\n",
    "test_targets = scaler_y.transform(test_df[[target_col]])\n",
    "\n",
    "sequence_length = 24 # 24 = one day, 168 = one week\n",
    "train_dataset = EnergyPriceDataset(train_features, train_targets, sequence_length)\n",
    "test_dataset = EnergyPriceDataset(test_features, test_targets, sequence_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26f534",
   "metadata": {},
   "source": [
    "# LSTM Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a25f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 219/219 [00:02<00:00, 96.72it/s, loss=0.0944] \n",
      "Epoch 2/100: 100%|██████████| 219/219 [00:01<00:00, 110.26it/s, loss=0.0794]\n",
      "Epoch 3/100: 100%|██████████| 219/219 [00:02<00:00, 108.41it/s, loss=0.0725]\n",
      "Epoch 4/100: 100%|██████████| 219/219 [00:02<00:00, 97.09it/s, loss=0.0629] \n",
      "Epoch 5/100: 100%|██████████| 219/219 [00:02<00:00, 107.12it/s, loss=0.0624]\n",
      "Epoch 6/100: 100%|██████████| 219/219 [00:01<00:00, 112.02it/s, loss=0.0594]\n",
      "Epoch 7/100: 100%|██████████| 219/219 [00:02<00:00, 108.56it/s, loss=0.0572]\n",
      "Epoch 8/100: 100%|██████████| 219/219 [00:02<00:00, 109.22it/s, loss=0.053] \n",
      "Epoch 9/100: 100%|██████████| 219/219 [00:02<00:00, 109.31it/s, loss=0.0489]\n",
      "Epoch 10/100: 100%|██████████| 219/219 [00:01<00:00, 111.59it/s, loss=0.0445]\n",
      "Epoch 11/100: 100%|██████████| 219/219 [00:02<00:00, 108.74it/s, loss=0.041] \n",
      "Epoch 12/100: 100%|██████████| 219/219 [00:02<00:00, 107.18it/s, loss=0.0385] \n",
      "Epoch 13/100: 100%|██████████| 219/219 [00:02<00:00, 109.00it/s, loss=0.0366]\n",
      "Epoch 14/100: 100%|██████████| 219/219 [00:01<00:00, 110.73it/s, loss=0.0351]\n",
      "Epoch 15/100: 100%|██████████| 219/219 [00:02<00:00, 106.99it/s, loss=0.034] \n",
      "Epoch 16/100: 100%|██████████| 219/219 [00:02<00:00, 108.55it/s, loss=0.0327]\n",
      "Epoch 17/100: 100%|██████████| 219/219 [00:02<00:00, 106.44it/s, loss=0.0328]\n",
      "Epoch 18/100: 100%|██████████| 219/219 [00:02<00:00, 108.57it/s, loss=0.0319]\n",
      "Epoch 19/100: 100%|██████████| 219/219 [00:02<00:00, 106.17it/s, loss=0.0339]\n",
      "Epoch 20/100: 100%|██████████| 219/219 [00:02<00:00, 107.51it/s, loss=0.0323]\n",
      "Epoch 21/100: 100%|██████████| 219/219 [00:02<00:00, 106.35it/s, loss=0.032] \n",
      "Epoch 22/100: 100%|██████████| 219/219 [00:02<00:00, 107.95it/s, loss=0.0301] \n",
      "Epoch 23/100: 100%|██████████| 219/219 [00:02<00:00, 108.85it/s, loss=0.0298] \n",
      "Epoch 24/100: 100%|██████████| 219/219 [00:02<00:00, 106.32it/s, loss=0.0318]\n",
      "Epoch 25/100: 100%|██████████| 219/219 [00:02<00:00, 108.70it/s, loss=0.0277] \n",
      "Epoch 26/100: 100%|██████████| 219/219 [00:02<00:00, 108.18it/s, loss=0.0303] \n",
      "Epoch 27/100: 100%|██████████| 219/219 [00:02<00:00, 106.22it/s, loss=0.0287] \n",
      "Epoch 28/100: 100%|██████████| 219/219 [00:02<00:00, 106.05it/s, loss=0.0283] \n",
      "Epoch 29/100: 100%|██████████| 219/219 [00:02<00:00, 108.28it/s, loss=0.0262] \n",
      "Epoch 30/100: 100%|██████████| 219/219 [00:02<00:00, 107.06it/s, loss=0.0255] \n",
      "Epoch 31/100: 100%|██████████| 219/219 [00:02<00:00, 106.00it/s, loss=0.0241]\n",
      "Epoch 32/100: 100%|██████████| 219/219 [00:02<00:00, 105.96it/s, loss=0.0251] \n",
      "Epoch 33/100: 100%|██████████| 219/219 [00:02<00:00, 105.72it/s, loss=0.0265] \n",
      "Epoch 34/100: 100%|██████████| 219/219 [00:02<00:00, 105.76it/s, loss=0.0219] \n",
      "Epoch 35/100: 100%|██████████| 219/219 [00:02<00:00, 108.27it/s, loss=0.0255] \n",
      "Epoch 36/100: 100%|██████████| 219/219 [00:02<00:00, 108.07it/s, loss=0.0354] \n",
      "Epoch 37/100: 100%|██████████| 219/219 [00:02<00:00, 105.49it/s, loss=0.0212] \n",
      "Epoch 38/100: 100%|██████████| 219/219 [00:02<00:00, 106.02it/s, loss=0.0156] \n",
      "Epoch 39/100: 100%|██████████| 219/219 [00:02<00:00, 107.68it/s, loss=0.0194] \n",
      "Epoch 40/100: 100%|██████████| 219/219 [00:02<00:00, 107.64it/s, loss=0.0179] \n",
      "Epoch 41/100: 100%|██████████| 219/219 [00:02<00:00, 105.59it/s, loss=0.0123] \n",
      "Epoch 42/100: 100%|██████████| 219/219 [00:02<00:00, 105.46it/s, loss=0.0133] \n",
      "Epoch 43/100: 100%|██████████| 219/219 [00:02<00:00, 107.63it/s, loss=0.0202] \n",
      "Epoch 44/100: 100%|██████████| 219/219 [00:02<00:00, 107.43it/s, loss=0.0116] \n",
      "Epoch 45/100: 100%|██████████| 219/219 [00:02<00:00, 105.75it/s, loss=0.0152] \n",
      "Epoch 46/100: 100%|██████████| 219/219 [00:02<00:00, 106.18it/s, loss=0.0101] \n",
      "Epoch 47/100: 100%|██████████| 219/219 [00:02<00:00, 104.34it/s, loss=0.0145] \n",
      "Epoch 48/100: 100%|██████████| 219/219 [00:02<00:00, 108.03it/s, loss=0.0142] \n",
      "Epoch 49/100: 100%|██████████| 219/219 [00:02<00:00, 104.75it/s, loss=0.0128] \n",
      "Epoch 50/100: 100%|██████████| 219/219 [00:02<00:00, 105.93it/s, loss=0.0127] \n",
      "Epoch 51/100: 100%|██████████| 219/219 [00:02<00:00, 105.61it/s, loss=0.0133] \n",
      "Epoch 52/100: 100%|██████████| 219/219 [00:02<00:00, 108.27it/s, loss=0.00686]\n",
      "Epoch 53/100: 100%|██████████| 219/219 [00:02<00:00, 105.91it/s, loss=0.0108] \n",
      "Epoch 54/100: 100%|██████████| 219/219 [00:02<00:00, 105.54it/s, loss=0.00819]\n",
      "Epoch 55/100: 100%|██████████| 219/219 [00:02<00:00, 107.62it/s, loss=0.0127] \n",
      "Epoch 56/100: 100%|██████████| 219/219 [00:02<00:00, 105.74it/s, loss=0.00759]\n",
      "Epoch 57/100: 100%|██████████| 219/219 [00:02<00:00, 105.76it/s, loss=0.0116] \n",
      "Epoch 58/100: 100%|██████████| 219/219 [00:02<00:00, 107.73it/s, loss=0.00917]\n",
      "Epoch 59/100: 100%|██████████| 219/219 [00:02<00:00, 105.61it/s, loss=0.0118] \n",
      "Epoch 60/100: 100%|██████████| 219/219 [00:02<00:00, 107.98it/s, loss=0.0131] \n",
      "Epoch 61/100: 100%|██████████| 219/219 [00:02<00:00, 108.04it/s, loss=0.0201] \n",
      "Epoch 62/100: 100%|██████████| 219/219 [00:02<00:00, 105.63it/s, loss=0.0179] \n",
      "Epoch 63/100: 100%|██████████| 219/219 [00:02<00:00, 107.39it/s, loss=0.0106] \n",
      "Epoch 64/100: 100%|██████████| 219/219 [00:02<00:00, 105.87it/s, loss=0.0197] \n",
      "Epoch 65/100: 100%|██████████| 219/219 [00:02<00:00, 105.22it/s, loss=0.0061] \n",
      "Epoch 66/100: 100%|██████████| 219/219 [00:02<00:00, 107.71it/s, loss=0.00537]\n",
      "Epoch 67/100: 100%|██████████| 219/219 [00:02<00:00, 107.58it/s, loss=0.0053] \n",
      "Epoch 68/100: 100%|██████████| 219/219 [00:02<00:00, 105.90it/s, loss=0.00876]\n",
      "Epoch 69/100: 100%|██████████| 219/219 [00:02<00:00, 105.98it/s, loss=0.00611]\n",
      "Epoch 70/100: 100%|██████████| 219/219 [00:02<00:00, 105.63it/s, loss=0.0108] \n",
      "Epoch 71/100: 100%|██████████| 219/219 [00:02<00:00, 107.22it/s, loss=0.0069] \n",
      "Epoch 72/100: 100%|██████████| 219/219 [00:02<00:00, 106.02it/s, loss=0.00594]\n",
      "Epoch 73/100: 100%|██████████| 219/219 [00:02<00:00, 105.95it/s, loss=0.00795]\n",
      "Epoch 74/100: 100%|██████████| 219/219 [00:01<00:00, 110.03it/s, loss=0.00757]\n",
      "Epoch 75/100: 100%|██████████| 219/219 [00:02<00:00, 105.23it/s, loss=0.0108] \n",
      "Epoch 76/100: 100%|██████████| 219/219 [00:02<00:00, 105.71it/s, loss=0.0084] \n",
      "Epoch 77/100: 100%|██████████| 219/219 [00:02<00:00, 107.99it/s, loss=0.00845]\n",
      "Epoch 78/100: 100%|██████████| 219/219 [00:02<00:00, 107.60it/s, loss=0.00474]\n",
      "Epoch 79/100: 100%|██████████| 219/219 [00:02<00:00, 104.68it/s, loss=0.00645]\n",
      "Epoch 80/100: 100%|██████████| 219/219 [00:02<00:00, 105.22it/s, loss=0.00936]\n",
      "Epoch 81/100: 100%|██████████| 219/219 [00:02<00:00, 107.83it/s, loss=0.0107] \n",
      "Epoch 82/100: 100%|██████████| 219/219 [00:02<00:00, 107.70it/s, loss=0.0072] \n",
      "Epoch 83/100: 100%|██████████| 219/219 [00:02<00:00, 105.89it/s, loss=0.00643]\n",
      "Epoch 84/100: 100%|██████████| 219/219 [00:02<00:00, 107.38it/s, loss=0.0108] \n",
      "Epoch 85/100: 100%|██████████| 219/219 [00:02<00:00, 103.66it/s, loss=0.00921]\n",
      "Epoch 86/100: 100%|██████████| 219/219 [00:02<00:00, 108.19it/s, loss=0.00644]\n",
      "Epoch 87/100: 100%|██████████| 219/219 [00:02<00:00, 108.05it/s, loss=0.00503]\n",
      "Epoch 88/100: 100%|██████████| 219/219 [00:02<00:00, 105.49it/s, loss=0.00468]\n",
      "Epoch 89/100: 100%|██████████| 219/219 [00:02<00:00, 105.14it/s, loss=0.00474]\n",
      "Epoch 90/100: 100%|██████████| 219/219 [00:02<00:00, 107.68it/s, loss=0.0118] \n",
      "Epoch 91/100: 100%|██████████| 219/219 [00:02<00:00, 107.97it/s, loss=0.0145] \n",
      "Epoch 92/100: 100%|██████████| 219/219 [00:02<00:00, 105.86it/s, loss=0.00599]\n",
      "Epoch 93/100: 100%|██████████| 219/219 [00:02<00:00, 104.99it/s, loss=0.00895]\n",
      "Epoch 94/100: 100%|██████████| 219/219 [00:02<00:00, 105.63it/s, loss=0.00834]\n",
      "Epoch 95/100: 100%|██████████| 219/219 [00:02<00:00, 107.53it/s, loss=0.00603]\n",
      "Epoch 96/100: 100%|██████████| 219/219 [00:02<00:00, 105.70it/s, loss=0.00995]\n",
      "Epoch 97/100: 100%|██████████| 219/219 [00:02<00:00, 107.80it/s, loss=0.00564]\n",
      "Epoch 98/100: 100%|██████████| 219/219 [00:02<00:00, 107.50it/s, loss=0.00445]\n",
      "Epoch 99/100: 100%|██████████| 219/219 [00:02<00:00, 105.82it/s, loss=0.00494]\n",
      "Epoch 100/100: 100%|██████████| 219/219 [00:02<00:00, 105.80it/s, loss=0.00541]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # just for a nice progress bar\n",
    "\n",
    "model = LSTM_model() # using default values\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for X_batch, y_batch in progress_bar: # pretty lol to loop over progress bar, but it holds an iterator over train_loader and its just the API of tqdm\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model.forward(X_batch)\n",
    "        loss = loss_func(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45653bbf",
   "metadata": {},
   "source": [
    "# Save for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45b7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "torch.save(model.state_dict(), 'lstm_model.pth')\n",
    "pickle.dump((scaler_X, scaler_y), open('scalers.pkl', 'wb')) # when we want to undo the scaling of the data, we need to know the used scaling parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
